[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mybook",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This book is my personal notes for stats, data and programming.\nI primarilly use it for notes around my statistics MSc.\nThis book has been created with Quarto through VSCode. I highly recommend it."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "survival.html",
    "href": "survival.html",
    "title": "3  Survival",
    "section": "",
    "text": "The following section is notes for survival analysis"
  },
  {
    "objectID": "survival.html#chapter-1---intro",
    "href": "survival.html#chapter-1---intro",
    "title": "4  Survival",
    "section": "4.1 Chapter 1 - Intro",
    "text": "4.1 Chapter 1 - Intro\nWe are interested in two types of cencoring\n\nright : The failure occurs after a set time, died after trial\nleft : The failure occurs before the observations begin, died before trial starts\n\nThe fundamental probaility theory required is as follows\n\n4.1.1 Distribution Function\nLet \\(T\\) be the failure time, where \\(T>0\\). Then as expected the distribution function is:\n\\(F(t) = P(T\\leq t)\\)\nAnd therefore the probability density is:\n\\(f(t) = F'(t)\\)\nAnd so\n\\(F(t) = \\int_0^tf(u)du\\)\n\n\n4.1.2 Survivor Function\nGenerally we are interested in whether someone will survive longer than a certain time. So:\n\\(S(t) = P(T\\geq t) = 1 - F(t) = \\int^{\\infty}_t f(u) du\\)\nAs it is linked to the distribution function we can therefore say\n\\(f(t) = -S'(t)\\)\n\n\n4.1.3 Hazard Function\nThe risk of death at time \\(t\\) given survival to time \\(t\\). Or the instantaenous risk of death at time \\(t\\)\n\\(h(t) = \\frac{f(t)}{S(t)}\\)\n\n\n4.1.4 Integrated Hazard Function\n\\(H(t) = \\int^{t}_0 h(u) du = -log(S(t))\\)\nSo\n\\(S(t) = e^{\\left(-H(t)\\right)}\\)\nand\n\\(f(t) = h(t)e^{\\left(-H(t)\\right)}\\)\n\n\n4.1.5 Limits worth knowing\n\\(f(t) = lim_{h \\rightarrow 0 } \\frac{P(t < T < t+h)}{h}\\)\nand\n\\(h(t) = lim_{h \\rightarrow 0 } \\frac{P(t \\leq T < t+h | T \\geq t)}{h}\\)"
  },
  {
    "objectID": "survival.html#we-are-primarily-interested-in",
    "href": "survival.html#we-are-primarily-interested-in",
    "title": "3  Survival",
    "section": "3.2 We are primarily interested in:",
    "text": "3.2 We are primarily interested in:"
  },
  {
    "objectID": "survival.html#chapter-2---distributions",
    "href": "survival.html#chapter-2---distributions",
    "title": "4  Survival",
    "section": "4.2 Chapter 2 - Distributions",
    "text": "4.2 Chapter 2 - Distributions\n\n4.2.1 Exponential\nThe only distribution with a constant hazard function.\n\\(T_i \\sim Exp(\\lambda, \\gamma)\\)\n\n\n\nProperty\nequation\n\n\n\n\n\\(f(t)\\)\n\\(\\lambda e^{-\\lambda t}\\)\n\n\n\\(F(t)\\)\n\\(1 - e^{-\\lambda t}\\)\n\n\n\\(S(t)\\)\n\\(e^{-\\lambda t}\\)\n\n\n\\(h(t)\\)\n\\(\\lambda\\)\n\n\n\n\n\n4.2.2 Weibull\nThe weibull can vary by implementation survreg uses the following implementation\n\\(T_i \\sim Weibull(\\lambda, \\gamma)\\)\nProperties should be given, TO BE VERIFIED\nIn this course:\n\n\\(\\lambda\\) is the shape\n\\(\\gamma\\) is the rate\n\nIt is extremely flexible, but can become unstable near \\(\\gamma = 1\\). From \\(\\gamma\\) we know the following:\n\n\\(\\gamma = 1\\) - Constant Hazard, becomes the exponential\n\\(\\gamma > 1\\) - Hazard INCREASES with time\n\\(\\gamma < 1\\) - Hazard DECREASES with time\n\nTODO - Add plot to get a feel for various hazrds, etc\n\nfrom scipy import stats\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nxs = np.arange(0,100,0.1)\ns_t = stats.expon(0,10).sf(xs)\nf_t = stats.expon(0,10).pdf(xs)\nplt.plot(xs,s_t)"
  },
  {
    "objectID": "survival.html#chapter-2---life-tables",
    "href": "survival.html#chapter-2---life-tables",
    "title": "4  Survival",
    "section": "4.3 Chapter 2 - Life Tables",
    "text": "4.3 Chapter 2 - Life Tables\nSee notes - Two example type to be practiced exhaustively (No loss and loss to follow up)\nLifetables tabulate death rates over a period of time. They are useful non-parametric summaries and help to inform which parametric models might be sensible.\nIn the loss to follow up we assume in this course that:\n\n\\(p_x\\) and \\(q_x\\) are constant over a time period, this is reasonable if short\nWe assume those who withdraw have the same probability of dieing as those who don’t\nWe assume withdrawls are evenly spaced through the year"
  },
  {
    "objectID": "survival.html#chapter-2---kaplan-meier",
    "href": "survival.html#chapter-2---kaplan-meier",
    "title": "4  Survival",
    "section": "4.4 Chapter 2 - Kaplan-Meier",
    "text": "4.4 Chapter 2 - Kaplan-Meier\n\nrnorm(1)\n\n[1] 1.380991"
  },
  {
    "objectID": "survival.html#chapter-3---two-sample",
    "href": "survival.html#chapter-3---two-sample",
    "title": "4  Survival",
    "section": "4.5 Chapter 3 - Two Sample",
    "text": "4.5 Chapter 3 - Two Sample\nKaplan-Meier is just a visual aid, we need to look at tests\n\n4.5.1 Log Rank Test\nNon-parametric.\n\\[ H_0 : S_1(t) = S_2(t)\\]\n\\[ H_A : S_1(t) \\neq S_2(t)\\]\n\\(H_A\\) is for some \\(t\\)\nSteps:\n\nCreate a table\ncreate an \\(i\\) column for 1,2,..n\ncreate a \\(t_i\\) column and list all the times of deaths only\nCreate an \\(r_{1,i}\\) and \\(r_{2,i}\\) for at risk (At risk for a time includes those who died at that time and all future censorees)\nSum \\(r_{1,i}\\) and \\(r_{2,i}\\) to get \\(r_i\\)\nCreate an \\(d_{1,i}\\) and \\(d_{2,i}\\) for death counts at the times\nSum the deaths to get \\(d_i\\)\nSum down death column to get observed \\(O_1\\) and \\(O_2\\)\nCalc \\(e_{1,i} = (\\frac{r_{1,i}}{r_i})d_i\\) and \\(e_{2,i}\\)\nSum the \\(e_{1,i}\\) and \\(e_{2,i}\\) to get \\(E_1\\) and \\(E_2\\)\nCalculate using below equation\n\n\\[ LR = \\frac{(O_1 - E_1)^2}{E_1} + \\frac{(O_2 - E_2)^2}{E_2} \\sim \\chi^2_{1}\\]\n\n\n4.5.2 Parametric"
  },
  {
    "objectID": "Clinical Trials.html",
    "href": "Clinical Trials.html",
    "title": "3  Chapter 1 - Intro",
    "section": "",
    "text": "4 Chapter 2 - Trial Design\nProtocol contains:\nProtocol deviations are to be expected, but must be recorded. There are two responses to deviation.\nCan always report both!\n“A null hypothesis which will be adopted unless there is significant evidence from the data that the alternate hypothesis is more viable.”\nThe test statistic has a sampling distribution, under the assumption \\(H_0\\) is true.\nCalculate the proability that the test statistics is as or more extreme than that observed. This is done with the sampling distribution.\nThe course has the following convention for the significance probability (p-value)\nIn this course a conclusion should be as follows:\nCare should be taken with p-value: - Even with substantial evidence, alternative may not actually be true - An effect can be statistically significant, but be too small to matter IRL - A large p-value does not mean alterbative is wrong. Could have two little data, poor design or by chance\nTests have assumptions!\nEssential ethically:\nSix steps:\nUseful notes:\nSome lessons from assignment:\nKey takeaways:\nIncreases risk of false positives. Medical trials are very expensive and ethically can only look at so many people, so tempting to fish.\nIn one test the p-value controls false positve risk. However in multiple tests, the problem becomes at least one.\nA 95% chance of not making an error, then two tests not making an error is \\(0.95^2 = 0.9025\\), so about 1 in 10 and so on. For 10 this becomes 40%. The general formula is, for k tests:\n\\(1-(1-\\alpha)^k\\)\nBonferonni correction is extremely conservative correctiuon based on rearranging it. The correction is:\n\\(\\frac{\\alpha}{k}\\)\nTo perfomr regression we estimate the Natural logarithm of the odds of success or Logit. Which is"
  },
  {
    "objectID": "Clinical Trials.html#two-sample-t-test",
    "href": "Clinical Trials.html#two-sample-t-test",
    "title": "3  Chapter 1 - Intro",
    "section": "7.1 Two-Sample T-Test",
    "text": "7.1 Two-Sample T-Test\nOne sample required if:\n\nComparing matched groups (difference from 0)\nComparing to a baseline, fixed value\n\n\nIdentify continuous\nDeclare independence and that population variance not known\nDeclare a two sample t-test\nIdentify subscripts with “Let X be”\nWrite that \\(H_0 : \\mu_X = \\mu_Y\\) and \\(H_A : \\mu_X \\neq \\mu_Y\\)\nCalculate N, \\(\\bar{X}\\) and \\(S^2_X\\)\nCalculate \\(\\nu = min(N_X, N_Y)\\)\nCalulate test statistic \\(T = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{S_X^2}{N_X} + \\frac{S_Y^2}{N_Y}}}\\)\n\\(T \\sim t_{\\nu}\\)\nLook up p value in tables (either neg or pos), DOUBLE IT, it’s two sided \\(P( |t_{\\nu}| > T)\\)\nCalulate the mean delta and find 95% (0.025-0.975) CI\n\nAs N gets big, t tends to normal, therefore 1.96 (approx. 2) becomes CI multiplier\nAssume normally distributed and independent samples"
  },
  {
    "objectID": "Clinical Trials.html#chi-square-test",
    "href": "Clinical Trials.html#chi-square-test",
    "title": "3  Chapter 1 - Intro",
    "section": "7.2 Chi-Square Test",
    "text": "7.2 Chi-Square Test\nUses:\n\nComparing two dicscrete groups\nDeciding whether two factors are independent\nTest a theory, eg. something can be modelled as a set ratio\n\n\nIdentify count based and that \\(\\chi_2\\) appropriate\nCalculate all row and column totals. Calculate overall total\nCalulate each \\(e_{ij} = \\frac{\\text{row total}\\times \\text{col total}}{\\text{Overall Total}}\\)\nCalulate \\(\\frac{(o_{ij}-e_{ij})^2}{e_{ij}}\\)\nSum them to get the test stat \\(X^2\\)\nState that \\(X^2 \\sim \\chi^2_{\\nu}\\)\n\\(\\nu = (\\text{n row - 1})\\times (\\text{n col - 1})\\)\nThis is a one sided test due to squaring!\nConvert the coloumns from counts to percents of column total for reporting\n\nTODO: Not worked beyond 5.4"
  },
  {
    "objectID": "Clinical Trials.html#further-notes",
    "href": "Clinical Trials.html#further-notes",
    "title": "3  Chapter 1 - Intro",
    "section": "7.3 Further Notes",
    "text": "7.3 Further Notes\n\n7.3.1 Multiple Testing\nJust comparing two groups relies heavily on well balanced randomisation.\nUsing multiple regression we can include and therefore account for covariates (prognostic factors), this is called an ANCOVA (Analysis of Covariance)\n\n\n7.3.2 One vs Two sided tests\nAlways, unless very strong prior knowledge, use a two sided test. One sided are more powerful.\nEg. If you think something will decrease and go one sided, but it actually increased you would miss it, potentailly missing a harmful effect.\n\n\n7.3.3 Pooled or seperate variance\nAlways seperate on the course:\n\nIf you use seperate and they are the same you will still get an unbiased estimateof common variance\nThis case would result in more DoF from welch approx, however this is slightly more conservative anyway\nHowever using pooled when not can get you very different DoF, whether pessimistic/optimistic is not possible to know without calcs\n\nWe use pooled on power tests otherwise it become impractical to assess.\n\n\n7.3.4 Testing for equality of variance\nDon’t:\n\nLow powered tests\nNon-sig does not mean equal, only weak evidence\nIf doing one test followed by another you are multiple testing ? TODO - p44 confusing answer I think hinting at multiple testing\n\nTODO 5.6"
  },
  {
    "objectID": "Clinical Trials.html#bradford-hill",
    "href": "Clinical Trials.html#bradford-hill",
    "title": "3  Chapter 1 - Intro",
    "section": "3.1 Bradford-Hill",
    "text": "3.1 Bradford-Hill\nIf all met does not mean causality, just sensible tests.\n\nTemporality - Effect follows cause\nConsistency - Does it happen in multiple groups (gender, countries, etc)\nCoherence - Do controlled and observational studies agree\nStrength of Association - Greater effect observed if given treatment\nBiological Gradient - More agent, more effect\nSpecificity - does agent specifically affect what it is applied to Eg. cream on hand, fixes hand\nPlausibility - Can it be explained mechanistically\nFreedom from bias/confounders\nAnalgous results elsewhere - similir agents have similar results"
  },
  {
    "objectID": "Clinical Trials.html#ethics",
    "href": "Clinical Trials.html#ethics",
    "title": "3  Chapter 1 - Intro",
    "section": "3.2 Ethics",
    "text": "3.2 Ethics\n\n3.2.1 Medical\nTrial design is key\n\nOnly trial if you genuinely don’t know whether one is better\nPoorly planned/exexuted (eg under powered) is very unethical\nPatients have informed consent\nPlacebos are ethical. The ethics of the population vs individual\nEthics commitee buys in\n\n\n\n3.2.2 Publication\nAlot of money at stake\n\nAvoid publication bias, only publishing good results\nJournal contributors must: declare full responsibilty held over trial, had access to data, made decision to publish."
  },
  {
    "objectID": "Clinical Trials.html#parrallel",
    "href": "Clinical Trials.html#parrallel",
    "title": "3  Chapter 1 - Intro",
    "section": "4.1 Parrallel",
    "text": "4.1 Parrallel\nk treatments, split into k groups. May aim for equal sized groups, though not mandatory.\nRequires large numbers to be sure of treatemtn effects. Robust to withdrawls"
  },
  {
    "objectID": "Clinical Trials.html#in-series",
    "href": "Clinical Trials.html#in-series",
    "title": "3  Chapter 1 - Intro",
    "section": "4.2 In Series",
    "text": "4.2 In Series\nAll patients, recieve all k treatments in same order. Allowing for in patient comparison.\nBenefits:\n\nPatient can express preferences\nPossiblity for simultaneous treatment\n\nIssues: - Patients may naturally imporve over time, making later treatments look better. Progressive disease act oppositely. - Carry over effects may exist, short term effects only - Withdrawls can be problematic - Some orders are impossible"
  },
  {
    "objectID": "Clinical Trials.html#carry-over",
    "href": "Clinical Trials.html#carry-over",
    "title": "3  Chapter 1 - Intro",
    "section": "4.3 Carry Over",
    "text": "4.3 Carry Over\nImproves upon in series to account for treatment, period, carryover.\nAll aptients get same treatements, but groups recieve in different order.\nIn the event of dropouts period one could be used as a parrallel study, though very low powered.\nWashout may be placed between treatments (no treatment window) to minimise carryover risk."
  },
  {
    "objectID": "Clinical Trials.html#factorial-design",
    "href": "Clinical Trials.html#factorial-design",
    "title": "3  Chapter 1 - Intro",
    "section": "4.4 Factorial Design",
    "text": "4.4 Factorial Design\nInvestigate effect of two or more treatments (factors), by giving combinations.\nEg 2x2. Each parient takes two drugs, where each drug has a placebo counterpart. Could take any combination of both drugs, one drug/one placebo, all placebo.\nMay be more efficent design. May also be prone to interactions, though this is of interest.\nMean response plots are useful for visualising effects:\n\nTwo parrallel lines, no interaction\nOne gradient increases more, quantitative interaction\nopposite gradianets, qualitative interation\n\nTODO : PRACTICE No interaction, qualitative, quantitative"
  },
  {
    "objectID": "Clinical Trials.html#sequential-design",
    "href": "Clinical Trials.html#sequential-design",
    "title": "3  Chapter 1 - Intro",
    "section": "4.5 Sequential Design",
    "text": "4.5 Sequential Design\nSimple form, aptients enter as pairs, and randomly allocated A or B.\nAssess which is better and move onto next pair. Cumulatively aggregate the prefference.\nYou will either cross a diverging boundary and stop early or reach end point and declare no difference.\nIt’s an ethical approach, detecting large differences quickly.\nHowever:\n\nNeed quick response times (before next pair)\nDropouts cause issues\nRequires constant attention\nBoundary calculation is complex"
  },
  {
    "objectID": "Clinical Trials.html#cross-over",
    "href": "Clinical Trials.html#cross-over",
    "title": "3  Chapter 1 - Intro",
    "section": "4.3 Cross Over",
    "text": "4.3 Cross Over\nImproves upon in series to account for treatment, period, carryover.\nAll aptients get same treatements, but groups recieve in different order.\nIn the event of dropouts period one could be used as a parrallel study, though very low powered.\nWashout may be placed between treatments (no treatment window) to minimise carryover risk."
  },
  {
    "objectID": "Clinical Trials.html#chapter-9---combining-trials",
    "href": "Clinical Trials.html#chapter-9---combining-trials",
    "title": "3  Chapter 1 - Intro",
    "section": "9.2 Chapter 9 - Combining trials",
    "text": "9.2 Chapter 9 - Combining trials\nTODO"
  },
  {
    "objectID": "Clinical Trials.html#chapter-10---comparing-measurement-methods",
    "href": "Clinical Trials.html#chapter-10---comparing-measurement-methods",
    "title": "3  Chapter 1 - Intro",
    "section": "9.3 Chapter 10 - Comparing measurement methods",
    "text": "9.3 Chapter 10 - Comparing measurement methods\nWe may want to change measurment equipment due to cost, speed, patient comfort, etc.\nTests are not always appropriate as highly correlated and not independent.\nMore interested in Bias (continuous) and agreement (discrete).\nNeither provide a statistical test, it is based on judgement.\n\n9.3.1 Bland Altman\n\nCalculate for each two measurements the difference and the mean\nCalulate the mean difference and the std\nReport a bias by mean difference with a CI (\\(\\bar{X} \\pm t_{0.975, \\nu} \\frac{\\sigma}{\\sqrt{N}}\\))\nCreate difference bands mean +/- 2sigma\nPlot scattter of x axis = avg, y axis = difference\nAdd 95% CI from 4 to the y axis as horizontal lines.\n\nYou are really interested in whether there is a difference from left to right.\n\n\n9.3.2 Kappa\nAgreement between\n\\(\\kappa =\\frac{A_{\\text{obs} - A_{\\text{exp}}}}{1 - A_{\\text{exp}}}\\)\n\n\n\nkappa\nstatement\n\n\n\n\n\\(\\kappa >0.75\\)\nExcellent Agreement\n\n\n\\(0.4<\\kappa <0.75\\)\nFair to good agreement\n\n\n\\(\\kappa <0.4\\)\npoor to moderate\n\n\n\nCalculate by:\n\nDo row and column totals, as well as overall total\n\\(A_{obs} = \\frac{\\text{sum of diagonal}}{\\text{Overall Total}}\\)\nCalc diagonal expected \\(\\frac{\\text{row total}\\times \\text{col total}}{\\text{Overall Total}}\\)\n\\(A_{exp}\\) is the sum of diagonal expected divided by overall total\n\nOnly care about leading diagonal as these are agreements\nIn some cases groups may have order, or there may be more than two assessors. Either way more advanced versions required."
  },
  {
    "objectID": "Clinical Trials.html#kappa-statement",
    "href": "Clinical Trials.html#kappa-statement",
    "title": "3  Chapter 1 - Intro",
    "section": "8.3 kappa | statement",
    "text": "8.3 kappa | statement\n\\(\\kappa >0.75\\) | Excellent Agreement \\(0.4<\\kappa <0.75\\) | Fair to good agreement \\(\\kappa <0.4\\) | poor to moderate"
  },
  {
    "objectID": "Clinical Trials.html#observational-studies",
    "href": "Clinical Trials.html#observational-studies",
    "title": "3  Chapter 1 - Intro",
    "section": "10.1 Observational studies",
    "text": "10.1 Observational studies\nThese are referred to as epidemiological studies\nRetrospective studies look at a control group who do not exhibit diesease and group who do. Comparing factors between groups.\nProspective studies follow up on a cohort of people who have had some exposure. Eg those with premature birth. They are then compared to the general population for some outcome. Eg. Very poor school grades.\nFor prospective, typically very large samples are used due to rare incidence typically of the disease. \\(\\chi^2\\) tests therefore are very powerful and flag very minor changes, without giving magnitude.\nTypically therefore work with Odds Ratios or Relative Risks and their respective CIs.\n\n10.1.1 Prospective - Relative Risk\nCreate following table\nWhere positive means, tests positive, not an good positive\n\n\n\nExposure\nPositive outcome\nNegative outcome\nTotal\n\n\n\n\nexposed\na\nb\na + b\n\n\nnot exposed\nc\nd\nc + d\n\n\n\nThen calc:\n\\(RR = \\frac{a(c+d)}{c(a+b)}\\)\nIf there was no difference RR would equal 1. So test whether CI contains 1.\nWorking in logs for ease:\nFirst, log the RR. Then calculate the Standard error of the log RR\n\\(\\text{S.E}[log(RR)] = \\sqrt{  \\frac{1}{a} -  \\frac{1}{a+b}+  \\frac{1}{c}-  \\frac{1}{c+d} }\\)\nCalc CI, using appropriate Z multiplier:\n\\(log(RR) \\pm 1.96 \\times \\text{S.E}[log(RR)\\).\nTake exponetial of everything to return to normal scale.\nIf contains 1 no evindence at 5% level\nRR <1 - risk is decreased by exposure RR > 1 - risk increased by exposure\n\n\n10.1.2 Retrospective - Odds Ratio\nOdds are ratio of\n\\(\\frac{P(\\text{Event occuring})}{P(\\text{Event not occuring})}\\)\nFirst construct table:\n\n\n\n.\nCasses\nControls\n\n\n\n\nExposed\na\nb\n\n\nNot Exposed\nc\nd\n\n\nTotal\na + c\nb + d\n\n\n\nOdds Ratio (OR) is as follows:\n\\(OR = \\frac{ad}{bc}\\)\nAgian, log SE\n\\(\\text{S.E}[log(OR)] = \\sqrt{  \\frac{1}{a} +  \\frac{1}{b}+  \\frac{1}{c}+  \\frac{1}{d} }\\)\nRepeat as per relative risk.\nIf above 1, raised risk.\nTODO 11.3 makes no sense? (it does but revisit)"
  },
  {
    "objectID": "Clinical Trials.html#exposure-posnegtotal",
    "href": "Clinical Trials.html#exposure-posnegtotal",
    "title": "3  Chapter 1 - Intro",
    "section": "9.2 Exposure |Pos|Neg|Total",
    "text": "9.2 Exposure |Pos|Neg|Total\nexposed | a | b | a + b not exposed | c | d | c + d —————————-"
  },
  {
    "objectID": "Clinical Trials.html#derivation",
    "href": "Clinical Trials.html#derivation",
    "title": "3  Chapter 1 - Intro",
    "section": "11.1 Derivation",
    "text": "11.1 Derivation\n\\(log(\\frac{P(Y_i = 1)}{P(Y_i = 0)})\\)\nTherefore to regress (omitting error term)\n\\(log(\\frac{P(Y_i = 1)}{P(Y_i = 0)}) = \\beta_0 + \\beta_1x_{i1} + ... + \\beta_px_{ip}\\)\nSimplifying (in this course they take intercept out front instead of 1s in the design matrix)\n\\(log(\\frac{P(Y_i = 1)}{P(Y_i = 0)}) = \\beta_0 + \\beta'\\mathbf{x}_i\\)\nLogging both sides leads to\n\\(\\frac{P(Y_i = 1)}{P(Y_i = 0)} = \\exp(\\beta_0 + \\beta'\\mathbf{x}_i)\\)\nand also\n\\(\\frac{P(Y_i = 1)}{P(Y_i = 0)} = \\exp(\\beta_0 + \\beta'\\mathbf{x}_i)\\)\nAnd so\n\\(P(Y_i = 1)= \\theta_i = \\frac{\\exp(\\beta_0 + \\beta'\\mathbf{x}_i)}{1+\\exp(\\beta_0 + \\beta'\\mathbf{x}_i)}\\)"
  },
  {
    "objectID": "Clinical Trials.html#treatment",
    "href": "Clinical Trials.html#treatment",
    "title": "3  Chapter 1 - Intro",
    "section": "11.2 Treatment",
    "text": "11.2 Treatment\nStandard practice is \\(\\beta_1\\) is treatement, where x is 0 = placebo or 1 = treatment. So treatment “turns on” \\(beta_1\\)\nPositive \\(\\beta_1\\) the odds of success are greater with treatment, negative means odds of success are greater in placebo."
  },
  {
    "objectID": "Clinical Trials.html#odds-ratio",
    "href": "Clinical Trials.html#odds-ratio",
    "title": "3  Chapter 1 - Intro",
    "section": "11.3 Odds ratio",
    "text": "11.3 Odds ratio\nSometimes Odds ratio is reffered to as relative risk as they are equivalent at small probabilities.\nOdds ratio of treatement can be calculated as\n\\(OR = \\exp(\\beta_1)\\)\nThis is derived from\n\\(\\frac{P(Y=1|x_1 = 1)}{P(Y=0|x_1 = 1)}/ \\frac{P(Y=1|x_1 = 0)}{P(Y=0|x_1 = 0)} = OR\\)\n\\(OR = \\exp(\\beta_1)\\) CAn also be used for other binary covariates, or two specicified continuous locations."
  },
  {
    "objectID": "Clinical Trials.html#partial-z-test",
    "href": "Clinical Trials.html#partial-z-test",
    "title": "3  Chapter 1 - Intro",
    "section": "11.4 Partial Z Test",
    "text": "11.4 Partial Z Test\n\\(H_0 : \\beta_j = 0\\)\nWhere:\n\\(\\frac{\\hat{\\beta_j}}{  \\sqrt{  \\hat{\\text{var}}(\\hat{\\beta_j)}  } } \\sim Z\\)\nThis is the SE \\(\\sqrt{\\hat{\\text{var}}(\\hat{\\beta_j)}}\\)\nIt is useful to know the following as SE may not be given\n$SE = \n## In exam\n\nGiven R output\nCalulcate Z, SE, p-value for all of interest if not already given\nState the direction of the coeeficent and the impact therefore on probability.\ncalulate the odds ratio by \\(\\exp(\\beta)\\)\nReport % increase/decrease in odds.\nUse SE to caluclate 95% CI for %$ and exponent to get CI for the OR, report as percentage increase/decrease"
  },
  {
    "objectID": "Clinical Trials.html#chapter-8--",
    "href": "Clinical Trials.html#chapter-8--",
    "title": "3  Chapter 1 - Intro",
    "section": "9.1 Chapter 8 -",
    "text": "9.1 Chapter 8 -\nNOT ON THE FORMULA SHEET!!!!!"
  },
  {
    "objectID": "Clinical Trials.html#historic",
    "href": "Clinical Trials.html#historic",
    "title": "3  Chapter 1 - Intro",
    "section": "6.1 Historic",
    "text": "6.1 Historic\nTODO p24"
  },
  {
    "objectID": "Clinical Trials.html#simple-randomisation",
    "href": "Clinical Trials.html#simple-randomisation",
    "title": "3  Chapter 1 - Intro",
    "section": "6.2 Simple Randomisation",
    "text": "6.2 Simple Randomisation\nGenerate or look up sequence of numbers. Bin the numbers into equally sized groups.\nIf there is surplus, eg 3 groups, 10 Rand No. Then ignore the designated surplus number and move to next.\nEg.\n0 1 6 7 3 2 6 8 9 5 3 2 2\nA : 1-3 B : 4-6 C : 7-9 0 : ignore and try again\nNegative :\n\nIn small trial balance can be poor\n\nPositive :\n\nCompletely unpredictable\nIn long run will create equal groups"
  },
  {
    "objectID": "Clinical Trials.html#blocking",
    "href": "Clinical Trials.html#blocking",
    "title": "3  Chapter 1 - Intro",
    "section": "6.3 Blocking",
    "text": "6.3 Blocking\nBlocking is where we create clusters of treatment assignments, to ensure balanced groups.\nEg. AB, BA 0-4 = AB 5-9 = BA\nJust move along the random numbers in sequence, don’t do every second, etc\nBlock size can be increased to make it harder to crack Eg\nAABB, ABBA, ABAB, BBAA, BABA, etc\nBlocking may be crackable with small block sizes and thus may risk double blindness.\nBlocking can also be used for imbalance setting.\nBlock size should be as large as possible to minimise risk of cracking. But not so large that the last block would be highly imbalanced if split as it reached the end."
  },
  {
    "objectID": "Clinical Trials.html#stratified-randomisation",
    "href": "Clinical Trials.html#stratified-randomisation",
    "title": "3  Chapter 1 - Intro",
    "section": "6.4 Stratified Randomisation",
    "text": "6.4 Stratified Randomisation\nTODO : Watch the video on this and verify below notes (I’m 99% sure they are good)\nTreatment (control included) groups should be as equal as possible in terms of patient characterirstics (Age, gender, etc). Imblances could confound treatments with characteristics. Solve with stratified randomisation.\nSay we have M/F, Over, under 50\n\n\n\nCat.\nSchema\n\n\n\n\nM, <50\nA B B A B B A A\n\n\nF, <50\nB A B A B A A B\n\n\nM, >50\nA B A B B A A B\n\n\nF, >50\nA B A B A B B A\n\n\n\nInstead of now applying patient count numbers, we move through the list of patients (which should itself be random), sequentially crossing off as we go."
  },
  {
    "objectID": "Clinical Trials.html#minimisation",
    "href": "Clinical Trials.html#minimisation",
    "title": "3  Chapter 1 - Intro",
    "section": "6.5 Minimisation",
    "text": "6.5 Minimisation"
  },
  {
    "objectID": "Clinical Trials.html#minimisationadaptive-randomisation",
    "href": "Clinical Trials.html#minimisationadaptive-randomisation",
    "title": "3  Chapter 1 - Intro",
    "section": "6.5 Minimisation/Adaptive randomisation",
    "text": "6.5 Minimisation/Adaptive randomisation\nWhere there are lots of factors strification can become impractical.\nMinimisation is dynamic assignment of patients to different treatments to achieve.\nSteps:\n\nCreate a table where first column is characteristics, second col is factor, all other columns are treatment tallys for the characteristics\nSum down the columns and look for lowest score\nAdd the patient to that group and update the tally\nRepeat\nIf score are equal, randomise.\n\nThis is not truely random and could lead to a level of prediction if the assignent history is known. To add randomisation you might add a probability of assignment to the smaller so if it is smaller there is some p between 0.5 and 1 whether it is assigned"
  },
  {
    "objectID": "Clinical Trials.html#chapter-8---crossover",
    "href": "Clinical Trials.html#chapter-8---crossover",
    "title": "3  Chapter 1 - Intro",
    "section": "9.1 Chapter 8 - Crossover",
    "text": "9.1 Chapter 8 - Crossover\nNOT ON THE FORMULA SHEET!!!!!\nCrossover trials offer more efficiency over parrallel due to within patient comparisons.\nTwo groups recieve two treatments but at different periods.\nPossible obsevred effects include:\n\nTreatment effects, what we are trying to find, a difference in treatments\nPeriod effect, different responses between periods could be due to seasonal effects or all patients improving over time\nCarryover (also know as treatement x period interaction)\n\nTODO - 8.2\n\n\n\nGroups\nPeriod 1\nPeriod 2\n\n\n\n\nGroup 1\nA , \\(Y_{11k}\\)\nB , \\(Y_{12k}\\)\n\n\nGroup 2\nB , \\(Y_{21k}\\)\nA , \\(Y_{22k}\\)\n\n\n\nWe model the following:\n\n\\(\\mu\\) - overall mean\n\\(\\tau_A , \\tau_B\\) - Treatment effects\n\\(\\pi_1, \\pi_2\\) - Period effects\n\\(\\lambda_1, \\lambda_2\\) - carryover effects\n\\(\\alpha_k\\) random patient effect \\(\\sim N(0, \\phi^2)\\) between patients\n\\(epsilon_{ijk}\\) independent random error\n\n\\(\\alpha\\) and \\(\\epsilon\\) disappear by taking expectations\nFrom this we can conclude that:\n\n\n\nGroups\nPeriod 1\nPeriod 2\n\n\n\n\nGroup 1\n\\(\\mu + \\tau_A + \\pi_1\\)\n\\(\\mu + \\tau_B + \\pi_2 + \\lambda_A\\)\n\n\nGroup 2\n\\(\\mu + \\tau_B + \\pi_1\\)\n\\(\\mu + \\tau_A + \\pi_2 + \\lambda_B\\)\n\n\n\n\n9.1.1 Workflow\nThere is more detail in the notes\n\n9.1.1.1 Assess Carryover\nIdeally carryover effects would be none or equal, so under\n\\(H_0 : \\lambda_A = \\lambda_B\\)\nSo two sample t-test\n\\(T = (Y_{i1k} +Y_{i2k})/2\\), the average across each patient\n\\(\\frac{\\bar{T_1} - \\bar{T_2}} {\\sqrt{  \\frac{S^2_{T_1}}{n_1} +  \\frac{S^2_{T_2}}{n_2} }} \\sim t_r\\)\nWhere\n\\(r = min(n_1, n_2)\\)\nSome info:\n\nWe don’t test that \\(H_0 : \\lambda_A = \\lambda_B= 0\\) as inseperable from period effects\nIt is low powered due to between patient comparison\nIf detected, results are contaminated, do not test for period and treatment, fallback to a parrallel study in period 1. Power however will be too low.\nIt is fine to use the sum of the two values for each patient over the average, the t test will be the same, just don’t have to divide by two.\n\n\n\n9.1.1.2 Assess Treatment\nAssumes no carryover\n\\(H_0 : \\tau_A = \\tau_B\\)\nThen \\(D_{ik} = Y_{i1k} - Y_{i2k}\\) calculated and as before\n\\(\\frac{\\bar{D_1} - \\bar{D_2}} {\\sqrt{  \\frac{S^2_{D_1}}{n_1} +  \\frac{S^2_{D_2}}{n_2} }} \\sim t_r\\)\n\n\n9.1.1.3 Assess Period\nAssumes no carryover\n\\(H_0 : \\pi_1 = \\pi_2\\)\nThen \\(D_{ik} = Y_{i1k} - Y_{i2k}\\) calculated and as before\n\\(\\frac{\\bar{D_1} - (-\\bar{D_2})} {\\sqrt{  \\frac{S^2_{D_1}}{n_1} +  \\frac{S^2_{D_2}}{n_2} }} \\sim t_r\\)\n\n\n9.1.1.4 Sample SIze\nSample size can be calulated as follows\nWhere n is the calculated number required for a parrallel arm and \\(\\rho\\) is the correlation between two measurments on each patient. So clearly less patient.\n\\(N = n(1-\\rho)\\)\nTODO 8.6 onwards"
  },
  {
    "objectID": "linear_models.html",
    "href": "linear_models.html",
    "title": "5  Linear Models",
    "section": "",
    "text": "weugfwj"
  },
  {
    "objectID": "linear_models.html#intro",
    "href": "linear_models.html#intro",
    "title": "5  Linear Models",
    "section": "5.1 Intro",
    "text": "5.1 Intro\nCategorical variables are called factors, they may be binary or have levels\ny may be reffered to as dependnent or response variable(s)\nx may be called independent , explanatory, predictor variables.\nWe use \\(n\\) to denote observations\nWe use \\(r\\) for the number of explanatory variables.\nA model might look like\n\\(y_i = \\beta_0 + \\beta_1x_{i1} + ... \\beta_{ir} + \\epsilon_i\\)\nThe \\(\\beta_0 + \\beta_1x_{i1} + ... \\beta_{ir}\\) is reffered to as the linear predictor. Epsilon is the random error.\nWhen r=2 we fit a plane! Then hyper-planes in higher dimensions.\nRemember a linear model is linear in the parameters (betas), it is allowed to include logs, quadratics.\nIt is easier to work in matrix notation. Parameter vector:\n\\(\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, ...)^T\\)\nThe \\(\\boldsymbol{x} = (x_1, x_2...)^T\\) is combined with a vector of ones to create the design matrix \\(\\boldsymbol{X}\\).\nThis combined creates\n\\(\\boldsymbol{y} = \\boldsymbol{X} \\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}\\)\n\\(\\boldsymbol{X}\\) has the shape \\(n \\times p\\)"
  },
  {
    "objectID": "survival_regression.html",
    "href": "survival_regression.html",
    "title": "6  Survival",
    "section": "",
    "text": "The first thing we are interested in is setting a baseline for the explanatory variables \\(\\textbf{x}\\). Where \\(\\textbf{x}\\) becomes the zero vector \\(\\textbf{0}\\). Eg. \\(\\textbf{x} = (0,0,0...,0)\\).\nIt is very common for age to be standardised around some age of interest. Eg 50, so all ages would be given as 5, -10, etc which equates to 55 and 40.\nThe two common methods are :\n\nAccelarated Failure Time (AFT)\nProportional Hazards (PH)"
  },
  {
    "objectID": "survival_regression.html#aft",
    "href": "survival_regression.html#aft",
    "title": "6  Survival",
    "section": "6.1 AFT",
    "text": "6.1 AFT\n\n6.1.1 Two Group Example\nIn the simplests case we model survival times \\(T\\) as a random variable. But with two groups we want to model them both as seperate RVs. Where the baseline RV is \\(T_0\\) and the treatment (or other covariate) is given by \\(T_1\\). As we now have times we can therefore model survivor functions \\(S\\). However in AFTs we don’t want \\(S_0\\) and \\(S_1\\) we want a single survivor function that is scaled.\nWe therefore look to the following:\n\\(\\text{Group 0 :   } S(t ; x_i=0) = P(T_0>t) = S_0(t))\\) \\(\\text{Group 1 :   } S(t ; x_i=1) = P(T_1>t) = P(\\frac{T_0}{\\psi}> t) = P(T_0>\\psi t) = S_0(\\psi t))\\)\nSo \\(\\psi\\) “accelrates time” and hence AFT and so the RVs are related by \\(T_1 = \\frac{T_0}{\\psi}\\) and so \\(S_1(t) = S_0(\\psi t)\\).\nThinking back to graphing, any multiplier of a function value is a stretch in x, whose magnitude is the reciprical. So a \\(\\psi >1\\) will shrink survival time by \\(\\frac{1}{\\psi}\\) and a \\(\\psi <1\\) will extend survival time.\nSo \\(\\psi >1\\) accelrates time for the patient (so they are more likely to die faster). Less than one Deaccelerates!\n\nScale factor is \\(\\frac{1}{\\psi}\\) , less than 1 means better survival times for the patient\n\nSo \\(\\psi\\) is a function of \\(\\textbf{x}\\), all of our covariates, which determine the “acceleration”\n\n\n6.1.2 Generalising to two groups\nInstead of now having a \\(\\psi\\) to turn on and off we now require \\(\\psi(\\textbf{x})\\) so that we can create a scaling factor for each individual. We therefore assume that (Where \\(S_0\\) is \\(S(t)\\) at the baseline consitions where \\(\\textbf{x} = \\textbf{0}\\)):\n\\(S(t;\\textbf{x}) = S_0(t\\psi(\\textbf{x}))\\)\nFrom this it can be shown that the following are true:\n\\(f(t;\\textbf{x}) = f_0(t\\psi(\\textbf{x}))\\psi(\\textbf{x})\\)\n\\(h(t;\\textbf{x}) = h_0(t\\psi(\\textbf{x}))\\psi(\\textbf{x})\\)\nThis can be derived by showing that that \\(t\\) being multiplie by \\(\\psi\\) and has \\(S_0\\) applied to it as a function. We know the relationship between the survival function and the density fuinction. \\(S(t) = 1- F(t)\\) differentiatiing we get negative density function. A function of a function, means that we need to use the chain rul and therefore gets the above. From the desnity we can get the hazard. TODO : Write out derivation. More details can be found at 25mins, 8/12.\nSo again: \\(T = \\frac{T_0}{\\psi(\\textbf{x})}\\)\nWe are yet to define \\(\\psi(\\textbf{x})\\) but tow conditions must be met:\n\n\\(\\psi(\\textbf{x})\\geq 0\\), so cannot have a negative time\n\\(\\psi(\\textbf{0}) = 1\\), so that the basline has no strethcing effects.\n\nFrom this a naturual choice is (it could be any functiion though):\n\\({\\psi(\\textbf{x})} = \\exp(-\\beta'\\textbf{x})\\)\nThis gives us our parameters, but excludes the intercept terms. Recalling \\(T = \\frac{T_0}{\\psi(\\textbf{x})}\\) then\n\\(E[T] = \\exp(\\beta'\\textbf{x})E[T_0]\\)\nIf \\(\\beta_i x_i\\) is positive then the expected survival time increases (good fro patient)\n\n\n6.1.3 Exponetial Case\nUsing the above we can therefore start to create an exponential AFT. We already know that for the exponential distribution:\n\n\n\n\n\n\n\n\nProperty\nequation\nAFT\n\n\n\n\n\\(S(t)_0\\)\n\\(e^{-\\lambda t}\\)\n\\(S(t;\\textbf{x}) = \\exp(-\\lambda t e^{-\\beta'\\textbf{x}})\\)\n\n\n\\(h(t)_0\\)\n\\(\\lambda\\)\n\\(\\lambda e^{-\\beta'\\textbf{x}}\\)\n\n\n\\(f(t)_0\\)\n\\(\\lambda e^{-\\lambda t}\\)\n\\(\\lambda e^{-\\beta'\\textbf{x}} \\exp(-\\lambda t e^{-\\beta'\\textbf{x}})\\)\n\n\n\nSo if \\(\\textbf{x}_i\\) is a p dimensional vector of explanatory variables then we ca n by MLE find p+1 parameters \\((\\lambda, \\beta_1, \\beta_2...\\beta_p)\\).\nMLE is found by usual method, get derivative, set to 0, solve iteratively. \\(\\hat{\\lambda}\\) and \\(\\hat{\\beta}\\) are found any by the asymptopic properties of the MLE we know that:\n\\(\\hat{\\lambda} \\sim N(\\lambda, \\text{Var}(\\hat{\\lambda}))\\)\nWe can obtain \\(\\text{Var}(\\hat{\\lambda}))\\) from the expected/observed stuff covered in chapter 3 (TODO: find this out!)"
  }
]
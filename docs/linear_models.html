<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>stats_notes - 5&nbsp; Linear Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./survival_regression.html" rel="next">
<link href="./survival.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Models</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">stats_notes</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Clinical Trials.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 1 - Intro</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survival</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_models.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Survival</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#intro" id="toc-intro" class="nav-link active" data-scroll-target="#intro"><span class="toc-section-number">5.1</span>  Intro</a></li>
  <li><a href="#chaprter-2---fit-estimate-and-residuals" id="toc-chaprter-2---fit-estimate-and-residuals" class="nav-link" data-scroll-target="#chaprter-2---fit-estimate-and-residuals"><span class="toc-section-number">5.2</span>  Chaprter 2 - Fit, estimate and residuals</a>
  <ul class="collapse">
  <li><a href="#estimator-mean-and-variance" id="toc-estimator-mean-and-variance" class="nav-link" data-scroll-target="#estimator-mean-and-variance"><span class="toc-section-number">5.2.1</span>  Estimator mean and variance</a></li>
  <li><a href="#error-variance-estimate" id="toc-error-variance-estimate" class="nav-link" data-scroll-target="#error-variance-estimate"><span class="toc-section-number">5.2.2</span>  Error variance estimate</a></li>
  <li><a href="#covariance" id="toc-covariance" class="nav-link" data-scroll-target="#covariance"><span class="toc-section-number">5.2.3</span>  covariance</a></li>
  </ul></li>
  <li><a href="#model-fit-coefficient-of-determination-r2" id="toc-model-fit-coefficient-of-determination-r2" class="nav-link" data-scroll-target="#model-fit-coefficient-of-determination-r2"><span class="toc-section-number">5.3</span>  Model Fit : Coefficient of determination <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#confidence-and-prediction-intervals" id="toc-confidence-and-prediction-intervals" class="nav-link" data-scroll-target="#confidence-and-prediction-intervals"><span class="toc-section-number">5.4</span>  Confidence and Prediction Intervals</a></li>
  <li><a href="#chapter-4---hypothesis-testing" id="toc-chapter-4---hypothesis-testing" class="nav-link" data-scroll-target="#chapter-4---hypothesis-testing"><span class="toc-section-number">5.5</span>  Chapter 4 - Hypothesis testing</a>
  <ul class="collapse">
  <li><a href="#some-eamples-of-c-and-c" id="toc-some-eamples-of-c-and-c" class="nav-link" data-scroll-target="#some-eamples-of-c-and-c"><span class="toc-section-number">5.5.1</span>  Some eamples of C and c</a></li>
  <li><a href="#test-stat-q-1" id="toc-test-stat-q-1" class="nav-link" data-scroll-target="#test-stat-q-1"><span class="toc-section-number">5.5.2</span>  Test Stat q &gt; 1</a></li>
  <li><a href="#test-stat-q-1-1" id="toc-test-stat-q-1-1" class="nav-link" data-scroll-target="#test-stat-q-1-1"><span class="toc-section-number">5.5.3</span>  Test Stat q = 1</a></li>
  <li><a href="#some-notes" id="toc-some-notes" class="nav-link" data-scroll-target="#some-notes"><span class="toc-section-number">5.5.4</span>  Some notes</a></li>
  <li><a href="#nested-models" id="toc-nested-models" class="nav-link" data-scroll-target="#nested-models"><span class="toc-section-number">5.5.5</span>  Nested models</a></li>
  <li><a href="#minimal-model" id="toc-minimal-model" class="nav-link" data-scroll-target="#minimal-model"><span class="toc-section-number">5.5.6</span>  Minimal model</a></li>
  <li><a href="#anova---application-in-r" id="toc-anova---application-in-r" class="nav-link" data-scroll-target="#anova---application-in-r"><span class="toc-section-number">5.5.7</span>  ANOVA - Application in R</a></li>
  </ul></li>
  <li><a href="#chapter-5" id="toc-chapter-5" class="nav-link" data-scroll-target="#chapter-5"><span class="toc-section-number">5.6</span>  Chapter 5</a>
  <ul class="collapse">
  <li><a href="#q-q-plot" id="toc-q-q-plot" class="nav-link" data-scroll-target="#q-q-plot"><span class="toc-section-number">5.6.1</span>  q-q plot</a></li>
  <li><a href="#homoscedasticity" id="toc-homoscedasticity" class="nav-link" data-scroll-target="#homoscedasticity"><span class="toc-section-number">5.6.2</span>  Homoscedasticity</a></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence"><span class="toc-section-number">5.6.3</span>  Independence</a></li>
  <li><a href="#formal-testing" id="toc-formal-testing" class="nav-link" data-scroll-target="#formal-testing"><span class="toc-section-number">5.6.4</span>  Formal testing</a></li>
  </ul></li>
  <li><a href="#chapter-6---interactions-and-factors" id="toc-chapter-6---interactions-and-factors" class="nav-link" data-scroll-target="#chapter-6---interactions-and-factors"><span class="toc-section-number">5.7</span>  Chapter 6 - Interactions and Factors</a>
  <ul class="collapse">
  <li><a href="#two-way-factors" id="toc-two-way-factors" class="nav-link" data-scroll-target="#two-way-factors"><span class="toc-section-number">5.7.1</span>  Two way factors</a></li>
  <li><a href="#interactions" id="toc-interactions" class="nav-link" data-scroll-target="#interactions"><span class="toc-section-number">5.7.2</span>  Interactions</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="linear_models.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Models</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="intro" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="intro"><span class="header-section-number">5.1</span> Intro</h2>
<p>Categorical variables are called factors, they may be binary or have levels</p>
<p>y may be reffered to as dependnent or response variable(s)</p>
<p>x may be called independent , explanatory, predictor variables.</p>
<p>We use <span class="math inline">\(n\)</span> to denote observations</p>
<p>We use <span class="math inline">\(r\)</span> for the number of explanatory variables.</p>
<p>A model might look like</p>
<p><span class="math inline">\(y_i = \beta_0 + \beta_1x_{i1} + ... \beta_{ir} + \epsilon_i\)</span></p>
<p>The <span class="math inline">\(\beta_0 + \beta_1x_{i1} + ... \beta_{ir}\)</span> is reffered to as the linear predictor. Epsilon is the random error.</p>
<p>When r=2 we fit a plane! Then hyper-planes in higher dimensions.</p>
<p>Remember a linear model is linear in the parameters (betas), it is allowed to include logs, quadratics.</p>
<p>It is easier to work in matrix notation. Parameter vector:</p>
<p><span class="math inline">\(\boldsymbol{\beta} = (\beta_0, \beta_1, ...)^T\)</span></p>
<p>The <span class="math inline">\(\boldsymbol{x} = (x_1, x_2...)^T\)</span> is combined with a vector of ones to create the design matrix <span class="math inline">\(\boldsymbol{X}\)</span>.</p>
<p>This combined creates</p>
<p><span class="math inline">\(\boldsymbol{y} = \boldsymbol{X} \boldsymbol{\beta}+ \boldsymbol{\epsilon}\)</span></p>
<p><span class="math inline">\(\boldsymbol{X}\)</span> has the shape <span class="math inline">\(n \times p\)</span></p>
<p><span class="math inline">\(\boldsymbol{\beta}\)</span> has the shape <span class="math inline">\(p \times 1\)</span></p>
<p>In linear modelling we assume that the <span class="math inline">\(\epsilon\)</span>:</p>
<ul>
<li>Is a MV Norm</li>
<li>0 Mean</li>
<li>Independent</li>
<li>Common variance <span class="math inline">\(\sigma^2\)</span> (homoscedasticity)</li>
</ul>
<p>So :</p>
<p><span class="math inline">\(\epsilon \sim N_n(0, \sigma^2 I_n)\)</span></p>
<p>And if <span class="math inline">\(y = X\beta + \epsilon\)</span> then we can say by linear transformation that</p>
<p><span class="math inline">\(y \sim N_n(X\beta, \sigma^2 I_n)\)</span></p>
<p>In this course:</p>
<ul>
<li>Explanatory - the base <span class="math inline">\(x\)</span> variable, from the data</li>
<li>Regressor - The constant, the $x $ and any function or transform of <span class="math inline">\(x\)</span> with a coefficient.</li>
</ul>
<p>So <span class="math inline">\(y = \beta_0 + \beta_1 x \beta_2 x^2\)</span> has a single explantory variable, but 3 regressors.</p>
</section>
<section id="chaprter-2---fit-estimate-and-residuals" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="chaprter-2---fit-estimate-and-residuals"><span class="header-section-number">5.2</span> Chaprter 2 - Fit, estimate and residuals</h2>
<p>Once fitted the the difference between the observed actual and fitted values (<span class="math inline">\(x_i^T\hat{\beta}\)</span>) is the residual. The vector of residuals therefore can be calced as:</p>
<p><span class="math inline">\(e = y - X\hat{\beta}\)</span></p>
<p>The <strong>sum of squared of the residuals</strong> or <strong>residual su of squares</strong> (<span class="math inline">\(S_r\)</span>) is very important</p>
<p><span class="math inline">\(S_r = S(\hat{\boldsymbol{\beta}}) = \sum_{i=1}^n e_i^2 =\textbf{e}^T\textbf{e} = (y - X\hat{\beta})^T(y - X\hat{\beta})\)</span></p>
<blockquote class="blockquote">
<p>In linalg rememeber that <span class="math inline">\(x^Tx\)</span> of a columnar vector is equivalent to <span class="math inline">\(\sum x^2_i\)</span></p>
</blockquote>
<p>This concept is very useful in linear modelling because through the MVNorm we can show that:</p>
<p><span class="math inline">\(L(\beta, \sigma^2 ; y) = f(y|\beta. \sigma^2) \propto \sigma^{-n}\exp(- \frac{1}{2\sigma^2}(y - X\hat{\beta})^T(y - X\hat{\beta}))\)</span></p>
<p>A key part of this derivation is that <span class="math inline">\(|\sigma^2I_n| = (\sigma^2)^n\)</span>. The log likelihood can be shown to be</p>
<p><span class="math inline">\(\ell(\beta, \sigma^2;y) = -nlog(\sigma) - \frac{1}{2\sigma^2}(y - X\hat{\beta})^T(y - X\hat{\beta}) + c\)</span></p>
<p>To maximise likelihood with respect to <span class="math inline">\(\beta\)</span> therefore we should be looking to minimise <span class="math inline">\(S_r\)</span>. Minimising this is the <strong>least squares</strong> method, which both mathematically and intuitively makes sense. There is an important consequence!</p>
<blockquote class="blockquote">
<p>Assuming X has rank p, the least squares estimator of <span class="math inline">\(\beta\)</span> is <span class="math inline">\(\hat{\beta} = (X^TX)^{-1}X^Ty\)</span></p>
</blockquote>
<p>When finding the MLE of <span class="math inline">\(\sigma^2\)</span> we find <span class="math inline">\(\frac{S_r}{n}\)</span>, however this is a biased estimator and instead we use <span class="math inline">\(\frac{S_r}{n-p}\)</span></p>
<section id="estimator-mean-and-variance" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="estimator-mean-and-variance"><span class="header-section-number">5.2.1</span> Estimator mean and variance</h3>
<p>Given <span class="math inline">\(y \sim N_n(X\beta, \sigma^2I_n)\)</span></p>
<p>Uisng this we can show that <span class="math inline">\(\hat{\beta}\)</span> is an unbiased estimator</p>
<p><span class="math inline">\(E(\hat{\beta}) = E((X^TX)^{-1}X^Ty)\)</span> where <span class="math inline">\(E(y) = X\beta\)</span> so</p>
<p><span class="math inline">\(E((X^TX)^{-1}X^TX\beta)\)</span> , the <span class="math inline">\(X^TX\)</span> terms cancel by inverse leaving <span class="math inline">\(\beta\)</span></p>
<p>Furthermore <span class="math inline">\(Var(\hat{\beta})\)</span> can be calculated:</p>
<p><span class="math inline">\(Var(\hat{\beta}) = Var((X^TX)^{-1}X^Ty)\)</span> where <span class="math inline">\(Var(y) = \sigma^2I_n\)</span></p>
<p>Recall that given a non-stochastic matrix <span class="math inline">\(A\)</span>, and stochastic y, then <span class="math inline">\(Var(Ay) = A Var(y) A^T\)</span>. From matrix laws too <span class="math inline">\((AB)^T = B^TA^T\)</span> and <span class="math inline">\((A^{-1})^T = (A^T)^{-1}\)</span></p>
<p><span class="math inline">\(Var(\hat{\beta}) = Var((X^TX)^{-1}X^Ty) = (X^TX)^{-1}X^T Var(y)((X^TX)^{-1}X^T)^T\)</span></p>
<p><span class="math inline">\(= (X^TX)^{-1}X^T Var(y) X((X^TX)^{-1})^T = (X^TX)^{-1}X^T Var(y) X((X^TX)^T)^{-1})\)</span></p>
<p><span class="math inline">\(= (X^TX)^{-1}X^T Var(y) X(X^TX)^{-1}\)</span></p>
<p><span class="math inline">\(= (X^TX)^{-1}X^T \sigma^2 I_n X(X^TX)^{-1}\)</span></p>
<p><span class="math inline">\(= \sigma^2 (X^TX)^{-1}X^TX(X^TX)^{-1} = \sigma^2 (X^TX)^{-1}\)</span></p>
<blockquote class="blockquote">
<p><span class="math inline">\(\hat{\beta} = N_p(\beta, \sigma^2 (X^TX)^{-1})\)</span></p>
</blockquote>
</section>
<section id="error-variance-estimate" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="error-variance-estimate"><span class="header-section-number">5.2.2</span> Error variance estimate</h3>
<p><span class="math inline">\(e = y-X\beta = y - X(X^TX)^{-1}X^Ty\)</span>, the <span class="math inline">\(y\)</span> can be factorised out to give</p>
<p><span class="math inline">\(e = My\)</span>, where <span class="math inline">\(M = I_n - X(X^TX)^{-1}X^T\)</span></p>
<p>If <span class="math inline">\(E(e) = E(My) = ME(y) = MX\beta\)</span></p>
<p><span class="math inline">\(MX = (I_n - X(X^TX)^{-1}X^T)X = X - X(X^TX)^{-1}X^TX = 0\)</span></p>
<p>So <span class="math inline">\(MX = 0\)</span> therefore <span class="math inline">\(E(e) = 0\)</span> . M is also <strong>idempotent</strong>, which means <span class="math inline">\(M^2 = M\)</span>. idempotent matrices (except <span class="math inline">\(I_N\)</span>) are always singular.</p>
<p>Another important result of M is that:</p>
<p><span class="math inline">\(Var(e) = Var(My) = MVar(y)M^T = M\sigma^2I_nM =\sigma^2M^2 = \sigma^2M\)</span></p>
<p>So <span class="math inline">\(M\)</span> is related to the variance-covariance matrix of the residuals.</p>
<blockquote class="blockquote">
<p>The variance of an individual residual is <span class="math inline">\(\sigma^2\)</span> times the corresponding diagonal of <span class="math inline">\(M\)</span></p>
</blockquote>
<p>It can be shown (using trace and rank rules) that:</p>
<p><span class="math inline">\(\hat{\sigma}^2 = \frac{1}{n-p}\sum^n_{i=1}e_i^2 = \frac{1}{n-p}S_r\)</span></p>
<p>The square root of this is the <strong>residual standard error</strong>, this is given in the r output.</p>
<p>It can also be shown by probability theory that a MVNorm with covariance matrix <span class="math inline">\(M\)</span>, that <span class="math inline">\(\frac{S_r}{\sigma^2} \sim \chi^2_{n-p}\)</span></p>
</section>
<section id="covariance" class="level3" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="covariance"><span class="header-section-number">5.2.3</span> covariance</h3>
<p>Rememeber that:</p>
<p><span class="math inline">\(corr(\beta_0, \beta_1) = \frac{Cov(\hat{\beta_0},\hat{\beta_1})}{se(\hat{\beta_0}) \times se(\hat{\beta_1)}}\)</span></p>
</section>
</section>
<section id="model-fit-coefficient-of-determination-r2" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="model-fit-coefficient-of-determination-r2"><span class="header-section-number">5.3</span> Model Fit : Coefficient of determination <span class="math inline">\(R^2\)</span></h2>
<p><span class="math inline">\(S_r\)</span> can be thought of as a measure of fit. However it will vary depending magnitudes of the variables, so cannot be compared directly between different problems. To enable better comparison we standardise with <span class="math inline">\(S_{yy}\)</span> (Total sum of squares), <span class="math inline">\(R^2\)</span> may also be called the coefficient of determination.</p>
<p><span class="math inline">\(R^2 = \frac{S_{yy} - S_r}{S_{yy}}\)</span> where <span class="math inline">\(S_{yy} = (y-\bar{y})^T(y-\bar{y}) = y^Ty - n\bar{y}^2\)</span></p>
<p>In simpler terms:</p>
<ul>
<li><span class="math inline">\(R^2\)</span> is the proportion of the total sum of squares that the model explains</li>
<li>Whilst <span class="math inline">\(S_r\)</span> is the explained part of <span class="math inline">\(S_{yy}\)</span></li>
</ul>
<p><span class="math inline">\(S_{yy}\)</span> may also be written as <span class="math inline">\(SS_{Total}\)</span></p>
<p>Relying on <span class="math inline">\(R^2\)</span> alone for model comparison is not sensible as it will always increase when parameters are added. The use of adjusted <span class="math inline">\(R^2\)</span> is preffereable as it takes into account the number of parameters.</p>
<p><span class="math inline">\(R^2(adj) = 1 - \frac{S_r/(n-p)}{S_{yy}/(n-1)}\)</span></p>
</section>
<section id="confidence-and-prediction-intervals" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="confidence-and-prediction-intervals"><span class="header-section-number">5.4</span> Confidence and Prediction Intervals</h2>
</section>
<section id="chapter-4---hypothesis-testing" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="chapter-4---hypothesis-testing"><span class="header-section-number">5.5</span> Chapter 4 - Hypothesis testing</h2>
<p>The most natural and simple hypothesis is whether a given <span class="math inline">\(\beta\)</span> is equal to 0. It has no effect on the model.</p>
<p>However there might be more general null hypothesis. Eg:</p>
<ul>
<li><span class="math inline">\(\beta_1 = \beta_2 = \beta_3 = 0\)</span></li>
<li><span class="math inline">\(\beta_1 = \beta_2\)</span></li>
</ul>
<p>To cover all bases (for linear hypothesis) however we can say:</p>
<p><span class="math inline">\(H_0 : \boldsymbol{C\beta} = c\)</span></p>
<p><span class="math inline">\(H_A : \boldsymbol{C\beta} \neq c\)</span> (At least one is not equal.)</p>
<p>C is <span class="math inline">\(q \times p\)</span> and c is <span class="math inline">\(q \times 1\)</span> of known constants. C has rank q, so full rank. So at each row of C and c we are asserting some hypothesis that the linear combination of C is equal to c.&nbsp;With this framework it is not possible to specify one-sided tests, though this is rarely of interest.</p>
<section id="some-eamples-of-c-and-c" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="some-eamples-of-c-and-c"><span class="header-section-number">5.5.1</span> Some eamples of C and c</h3>
<p><span class="math inline">\(H_0 : \beta_1 = 1, \beta_2=2\)</span></p>
<p><span class="math inline">\(C = \begin{pmatrix} 0 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 1 \end{pmatrix} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\)</span></p>
<p><br>
</p>
<p><span class="math inline">\(H_0 : \beta_1 = \beta_2 = 0\)</span></p>
<p><span class="math inline">\(C = \begin{pmatrix} 0 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)</span></p>
<p><br>
</p>
<p><span class="math inline">\(H_0 : \beta_2 = 0\)</span></p>
<p><span class="math inline">\(C = \begin{pmatrix} 0 &amp; 0 &amp; 1 \end{pmatrix} = \begin{pmatrix} 0 \end{pmatrix}\)</span></p>
<p><br>
</p>
<p><span class="math inline">\(H_0 : \beta_2 = 3\)</span></p>
<p><span class="math inline">\(C = \begin{pmatrix} 0 &amp; 0 &amp; 1 \end{pmatrix} = \begin{pmatrix} 3 \end{pmatrix}\)</span></p>
<p><br>
</p>
<p><span class="math inline">\(H_0 : \beta_1 = \beta_2\)</span> Which is equivalent to <span class="math inline">\(H_0 : \beta_1 - \beta_2 = 0\)</span></p>
<p><span class="math inline">\(C = \begin{pmatrix} 0 &amp; 1 &amp; -1 \end{pmatrix} = \begin{pmatrix} 0 \end{pmatrix}\)</span></p>
</section>
<section id="test-stat-q-1" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="test-stat-q-1"><span class="header-section-number">5.5.2</span> Test Stat q &gt; 1</h3>
<p><span id="eq-f-test"><span class="math display">\[\frac{(C \hat{\beta} -c )^T(C(X^TX)^{-1}C^T)^{-1}(C \hat{\beta} -c )}{q\hat{\sigma}^2} \sim F_{q, n-p} \tag{5.1}\]</span></span></p>
<p>Note : This is a one-sided test so <span class="math inline">\(1-\alpha\)</span> (0.95) not <span class="math inline">\(1-\alpha / 2\)</span> (0.975, 95% CI). This is due to square terms.</p>
</section>
<section id="test-stat-q-1-1" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="test-stat-q-1-1"><span class="header-section-number">5.5.3</span> Test Stat q = 1</h3>
<p>When there is only one test eg. <span class="math inline">\(\beta_1=0\)</span> then the abiove equation can be simplified to a t-test. This becomes:</p>
<p><span class="math inline">\(\frac{\hat{\beta}_i - c_i}{\hat{\sigma} \sqrt{g_{ii}}} \sim t_{n-p}\)</span></p>
<p>Where <span class="math inline">\(G = (X^TX)^{-1}\)</span> and <span class="math inline">\(g_{ii}\)</span> is the <em>i</em>-th diagonal term.</p>
</section>
<section id="some-notes" class="level3" data-number="5.5.4">
<h3 data-number="5.5.4" class="anchored" data-anchor-id="some-notes"><span class="header-section-number">5.5.4</span> Some notes</h3>
<p>The r <code>summary</code> will tell you <span class="math inline">\(\hat{\sigma}\)</span> through the “Residual Standard Error” line</p>
<p>The F-Statistic in <code>summary</code> is testing whether all coefficients other than intercept are 0</p>
<p>Pay little attention to tests of the individual coefficients if doing multi coeefficent tests. Significance can easily flip between all and individuals. Even if all are indicating p&gt;0.05 and test says p&gt;0.05.</p>
</section>
<section id="nested-models" class="level3" data-number="5.5.5">
<h3 data-number="5.5.5" class="anchored" data-anchor-id="nested-models"><span class="header-section-number">5.5.5</span> Nested models</h3>
<p>By nested models we mean comparing one model to another, where one of them contains a subset of the other. It is usually used to determine whether there is value in including the term in the term(s) in the model.</p>
<p>We are trying to trade off increasing regression sum of squares vs excluding the term. So there is value in verifying whether something should be included.</p>
<p>An example is:</p>
<p><span class="math inline">\(y= \beta_0 + \beta_1x_1\)</span> vs <span class="math inline">\(y= \beta_0 + \beta_1x_1 + \beta_2 x^2\)</span></p>
<p>So does <span class="math inline">\(\beta_2 = 0\)</span>?</p>
<p>For nested models we use a similar framework to before but modify the <span class="math inline">\(\beta\)</span> vector. The C matrix becomes a 0 matrix with the indentity matrix appended to the right where the <span class="math inline">\(I_n\)</span> has an n of <span class="math inline">\(p_f - p_r\)</span> where <span class="math inline">\(p_f\)</span> is parameter in the full model and <span class="math inline">\(p_r\)</span> is the number of params in the reduced model.</p>
<p>In <span class="math inline">\(\boldsymbol{\beta}\)</span> we have a stack of vectors <span class="math inline">\((\boldsymbol{\beta}_1, \boldsymbol{\beta}_2)^T\)</span>. Where <span class="math inline">\((\boldsymbol{\beta}_1\)</span> is a <span class="math inline">\(p_r \times 1\)</span> and <span class="math inline">\((\boldsymbol{\beta}_2\)</span> is a <span class="math inline">\((p_f - p_r) \times 1\)</span>.</p>
<p>Element order is arbituary provided that we are consistent between all matrices and vectors.</p>
<p>A useful summary is via ANOVA tables where:</p>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 23%">
<col style="width: 5%">
<col style="width: 20%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Source of Variation</th>
<th>Sum of Squares (SS)</th>
<th>DoF</th>
<th>Mean Square (MS)</th>
<th>Mean Square Ratio (MSR)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Due to <span class="math inline">\(X_1\)</span> is <span class="math inline">\(\beta_2\)</span> = 0</td>
<td><span class="math inline">\(S_1\)</span></td>
<td><span class="math inline">\(p_r\)</span></td>
<td><span class="math inline">\(S_1 / p_r\)</span></td>
<td><span class="math inline">\(F_1\)</span></td>
</tr>
<tr class="even">
<td>Due to <span class="math inline">\(X_2\)</span> only</td>
<td><span class="math inline">\(S_2\)</span></td>
<td><span class="math inline">\(p_f - p_r\)</span></td>
<td><span class="math inline">\(S_2 /(p_f - p_r)\)</span></td>
<td><span class="math inline">\(F_2\)</span></td>
</tr>
<tr class="odd">
<td>Residual</td>
<td><span class="math inline">\(S_r\)</span></td>
<td><span class="math inline">\(n -p_f\)</span></td>
<td><span class="math inline">\(\hat{\sigma}^2\)</span></td>
<td><span class="math inline">\(F_2\)</span></td>
</tr>
<tr class="even">
<td>Total</td>
<td><span class="math inline">\(y^Ty\)</span></td>
<td>n</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The MSR are calculated by dividing the variance of each model by the product of the Dof and residuals so:</p>
<p><span class="math inline">\(F_2 = \frac{S_2}{(p_f-p_r)\hat{\sigma}^2}\)</span></p>
<p><span class="math inline">\(F_1 = \frac{S_1}{p_r\hat{\sigma}^2}\)</span></p>
<p>We typically work through these tests in sequence, firstly test 2 then test 1.</p>
<p>The initial test on <span class="math inline">\(F_2\)</span> is just the test in <a href="#eq-f-test">Equation&nbsp;<span>5.1</span></a>. Where the null is <span class="math inline">\(\beta_2 = 0\)</span> and the null dist is <span class="math inline">\(F_{p_f-p_r, n-p_f}\)</span> (remember it’s one sided) and we test if <span class="math inline">\(F_2 &gt;F_{p_f-p_r, n-p_f}\)</span>. <span class="math inline">\(F_2\)</span> can also be calculated from residual sum of squares of models (RSS,, which can be obtained from ANOVA summary in R).</p>
<p><span id="eq-exam-f"><span class="math display">\[F_2 = \frac{(RRS_r - RSS_f) / (p_f - p_r)}{(RSS_f)/(n-p_f)} \tag{5.2}\]</span></span></p>
<p>After <span class="math inline">\(\beta_2\)</span> we test the hypothesis that <span class="math inline">\(\beta_1=0\)</span> given we know <span class="math inline">\(\beta_1\)</span> is 0, or <span class="math inline">\(\boldsymbol{\beta}=\textbf{0}\)</span> (this is a little handwavy as the test doesn’t poove the null, but it is accepted convention).</p>
<p>We test <span class="math inline">\(F_1 &gt; F_{p_r, n-p_f}\)</span></p>
</section>
<section id="minimal-model" class="level3" data-number="5.5.6">
<h3 data-number="5.5.6" class="anchored" data-anchor-id="minimal-model"><span class="header-section-number">5.5.6</span> Minimal model</h3>
<p>A special test based on the previous section. If we set <span class="math inline">\(c=0\)</span> and <span class="math inline">\(C=I\)</span> we would test that every single coefficient is equal to zero. This basically tests that y is 0 and constant irrespetive of the variables. What we really want to test howeveris that y has a floating mean, but is constant.</p>
<p>Therefore we test that the regressors only are zero by saying <span class="math inline">\(\beta_1 = \beta_0\)</span> and that the <span class="math inline">\(\beta_2\)</span> is just all the regressors, making a p-1 length. The <span class="math inline">\(\beta_0\)</span> model is called the minimal or null model, with a mean of <span class="math inline">\(\beta_0\)</span> and variance of <span class="math inline">\(\sigma^2\)</span>. As we don’t really care if <span class="math inline">\(beta_0\)</span> is 0 or not we exclude it from the ANOVA tables.</p>
<p>TODO: read this https://stats.stackexchange.com/questions/256726/linear-regression-what-does-the-f-statistic-r-squared-and-residual-standard-err</p>
<p>So in this model <span class="math inline">\(p_r=1\)</span> and <span class="math inline">\(p_f = p-1\)</span></p>
<p>It can be show (see notes p29) that:</p>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 23%">
<col style="width: 5%">
<col style="width: 20%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Source of Variation</th>
<th>Sum of Squares (SS)</th>
<th>DoF</th>
<th>Mean Square (MS)</th>
<th>Mean Square Ratio (MSR)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Due to regressors</td>
<td><span class="math inline">\(S_2 = \hat{\beta}^TX^TX\hat{\beta} - n \bar{y}^2\)</span></td>
<td><span class="math inline">\(p-1\)</span></td>
<td><span class="math inline">\(S_2 / (p-1)\)</span></td>
<td><span class="math inline">\(F\)</span></td>
</tr>
<tr class="even">
<td>Residual</td>
<td><span class="math inline">\(S_r = y^Ty -\hat{\beta}^TX^TX\hat{\beta}\)</span></td>
<td><span class="math inline">\(n -p\)</span></td>
<td><span class="math inline">\(\hat{\sigma}^2\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(S_{yy} =y^Ty - n\bar{y}^2\)</span></td>
<td>n-1</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>So <span class="math inline">\(F = \frac{S_2}{(p-1)\hat{\sigma}^2}\)</span> where null is <span class="math inline">\(F_{p-1, n-p}\)</span></p>
<p>TODO: what are they talking about top of p30</p>
</section>
<section id="anova---application-in-r" class="level3" data-number="5.5.7">
<h3 data-number="5.5.7" class="anchored" data-anchor-id="anova---application-in-r"><span class="header-section-number">5.5.7</span> ANOVA - Application in R</h3>
<blockquote class="blockquote">
<p>This is highly likley to be examined</p>
</blockquote>
<p>With r you have two choices for ANOVA one where you enter each model seperately where one model is the baseline and the other is more complex so :</p>
<ul>
<li><span class="math inline">\(y = \beta_0 + \beta_1x_1\)</span> (mdl_1)</li>
<li><span class="math inline">\(y = \beta_0 + \beta_1x_1 + \beta_2x_1^2\)</span> (mdl_2)</li>
</ul>
<p>so <code>anova(mdl_1, mdl_2)</code> or you simply run <code>anova(mdl_2)</code>.</p>
<p>In the first option it automatically detects the extra terms and assigns those to <span class="math inline">\(\beta_2\)</span> and then <span class="math inline">\(H_0: \beta_2 = 0\)</span> is assessed. Values from the summary of this can readily be placed into <a href="#eq-exam-f">Equation&nbsp;<span>5.2</span></a>.</p>
<p>TODO : Down from the blue arrow</p>
</section>
</section>
<section id="chapter-5" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="chapter-5"><span class="header-section-number">5.6</span> Chapter 5</h2>
<p>Remember:</p>
<p><span class="math inline">\(\epsilon_i = y_i - \textbf{x}_i^T\boldsymbol{\beta}\)</span></p>
<p>We assume that <span class="math inline">\(\epsilon_i\)</span> is:</p>
<ul>
<li>0 mean, there is no systematic error from <span class="math inline">\(\textbf{X}\boldsymbol{\beta}\)</span></li>
<li>Independent</li>
<li>Common variance - homoscedasticity</li>
<li>Normaly distributed</li>
</ul>
<p>We check these through residuals (the estimate of the error based on fitted model). If the model were to be correct they would be normally distributed, however they are not independent or with common variance. Unequal variances can be corrected for by standardised residuals:</p>
<p><span class="math inline">\(s_i \frac{e_i}{\sqrt{\hat{\text{Var}}(e_i)}} \sim t_{n-p}\)</span> where <span class="math inline">\(\hat{\text{Var}}(e_i)\)</span> is the estimate of variance</p>
<blockquote class="blockquote">
<p>observed residuals are not independent and do not have equal variances</p>
</blockquote>
<section id="q-q-plot" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="q-q-plot"><span class="header-section-number">5.6.1</span> q-q plot</h3>
<p>Plots quantiles of observed vs expected and you should get a straight line, you may plot:</p>
<ul>
<li>Standard Normal against observed data</li>
<li>Normal with mean and variance of observed against observed data</li>
<li>Standardised residual</li>
</ul>
<p>You should see a straight line of plots if the fit is appropriate. If:</p>
<ul>
<li>The plot is bowed there is skew</li>
<li>Down left/Up right = heavier tails</li>
</ul>
<p>Histograms should be avoided if the dataset is small.</p>
</section>
<section id="homoscedasticity" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="homoscedasticity"><span class="header-section-number">5.6.2</span> Homoscedasticity</h3>
<p>Plot a scatter graph of residual against the fitted value (y predicted). This should be a uniform band. Typically issues arise where the results fan outwards to the larger values</p>
</section>
<section id="independence" class="level3" data-number="5.6.3">
<h3 data-number="5.6.3" class="anchored" data-anchor-id="independence"><span class="header-section-number">5.6.3</span> Independence</h3>
<p>Typically we plot the residual in observed order, through an “index plot”. The order is based on SME knowledge (time, distance,etc). We are looking for trends, closely linked order points, etc.</p>
</section>
<section id="formal-testing" class="level3" data-number="5.6.4">
<h3 data-number="5.6.4" class="anchored" data-anchor-id="formal-testing"><span class="header-section-number">5.6.4</span> Formal testing</h3>
<p>We can formally test whether the residuals contain outliers by standardising the residuals and looking for points. If the standardised residuals (<span class="math inline">\(s_i\)</span>) are t distributed we can assess how “likely” they are by assessing the quantiles.</p>
<p>However if we were to do this for every point we are multiple testing and so a corrrection to the cut off should be applied.Formally:</p>
<p><span class="math inline">\(|s_i| &gt; t_{n - p, 1-\alpha/2}\)</span></p>
<p>Instead of the bonferonni test we could use the Šidák correction which is:</p>
<blockquote class="blockquote">
<p><span class="math inline">\(\alpha^* = 1 - (1-\alpha)^{1/n}\)</span>, where <span class="math inline">\(\alpha^*\)</span> is the adjusted stat.</p>
</blockquote>
</section>
</section>
<section id="chapter-6---interactions-and-factors" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="chapter-6---interactions-and-factors"><span class="header-section-number">5.7</span> Chapter 6 - Interactions and Factors</h2>
<p>We include factors through the use of dummy or indicator variables. Where the are two levels this will simply be a 0/1. For more than one catergory, one-hot encoding will be used.</p>
<p>With dummy variables you have to be very careful not to over parameterise the model.</p>
<p>You cannot have a model constant and a constant for each factor this is overparameterisation and leads to multicolinearity. A matrix is not full rank when there are linear combinations. Therefore <span class="math inline">\(X^TX\)</span> is no longer invertable (singular). Therefore we cannot calculate <span class="math inline">\(\hat{\beta}\)</span> through <span class="math inline">\((X^TX)^{-1}X^T y\)</span>.</p>
<p>The solution is to move to the following representation:</p>
<p><span class="math inline">\(y_{ij} = \mu + \alpha_i + \epsilon_{ij}\)</span></p>
<p>This can be implement one of two ways</p>
<section id="level-one-zero-constraint" class="level4" data-number="5.7.0.1">
<h4 data-number="5.7.0.1" class="anchored" data-anchor-id="level-one-zero-constraint"><span class="header-section-number">5.7.0.1</span> Level One Zero Constraint</h4>
<p>Also known as <strong>corner points constraints</strong>. Essentially the first catergorcial variable is used for <span class="math inline">\(\mu\)</span> and the first <span class="math inline">\(\alpha_1\)</span> is set to zero removing it from the model and the design matrix.</p>
<p>All other <span class="math inline">\(\alpha_i\)</span> i=(2,3,…k) are therefore deviations from the mean (<span class="math inline">\(\mu\)</span>) and hence how the mean of y changes as we move between factors.</p>
<p><code>options(contrast=c(factor= ..., ordered =...))</code> will implement this in R</p>
</section>
<section id="sum-to-zero" class="level4" data-number="5.7.0.2">
<h4 data-number="5.7.0.2" class="anchored" data-anchor-id="sum-to-zero"><span class="header-section-number">5.7.0.2</span> Sum to Zero</h4>
<p>An alternative where all of the <span class="math inline">\(\alpha\)</span> values are designed to sum to zero. In a one factor model the <span class="math inline">\(\mu\)</span> is therefore the overall mean, while <span class="math inline">\(\alpha\)</span> is the factor group means deviation from the this.</p>
<p>This method does remove a parameter, it is achievd by accounting for the sum of all alphas from 1 to k-1 and setting k equal to the negative sum of these so they cancel. X therefore loses it’s <span class="math inline">\(\alpha_k\)</span> column, but also modifies all other <span class="math inline">\(alpha_i\)</span> columns where the <strong>row</strong> is i=k</p>
<p>TODO: This is a bit lost on me, see p46/47</p>
</section>
<section id="two-way-factors" class="level3" data-number="5.7.1">
<h3 data-number="5.7.1" class="anchored" data-anchor-id="two-way-factors"><span class="header-section-number">5.7.1</span> Two way factors</h3>
<p>In the two way factor you have rows and columns. In the corner point constraint the mean is set by the top left mean. Then an $ deviation is reported for 2,3,…k rows and a <span class="math inline">\(\beta\)</span> for 2,3,…k columns.</p>
</section>
<section id="interactions" class="level3" data-number="5.7.2">
<h3 data-number="5.7.2" class="anchored" data-anchor-id="interactions"><span class="header-section-number">5.7.2</span> Interactions</h3>
<p>Interactions are non additive effects of one variable on anaother, this is most commonly achieved through multiplication. These terms can be tested for significance using <code>summary</code> or nested comparisions conducted with <code>anova</code>. Care must be taken with factors as it is easy to get high number of combinations, inflate <span class="math inline">\(R^2\)</span> through overfitting or get muktiplicity problems with signiificance.</p>
<blockquote class="blockquote">
<p>When you can an interaction in <code>R</code> you are not just creating a mutliplying term, but also including that interaction terms as standalone variables themselves</p>
</blockquote>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./survival.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survival</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./survival_regression.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Survival</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>